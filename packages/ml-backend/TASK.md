# ML Backend (MVP / Pet Project)

Минимальный сервис обучения (Node.js + tfjs) для игры: принимает опыт, обучает модель, раздаёт веса. Цель — быстро получить рабочий цикл, без продакшен-избыточности.

## Текущее упрощение
- Один поток: убраны воркеры и BroadcastChannel → заменено на простой RxJS Subject shim.
- Метрики (визуализация/каналы) отключены: код отправки закомментирован, чтобы можно было легко включить снова.
- Конфигурация: логика в `config.ts`, в `.env` — только секреты/окружение (например `ABLY_API_KEY`).
- Нет сложного оркестратора / менеджеров состояний — прямой линейный цикл.
- Чекпоинты в простой директории без ротации на первом этапе.

### Политика изменений / Scope
Стараемся НЕ трогать собственно логику обучения (архитектура сетей, вычисление потерь, advantages, v-trace и т.п.), кроме минимально необходимого для запуска в Node.js. Фокус изменений:
- Транспорт и приём: подписка/получение опыта, публикация версий модели.
- Инфраструктура: миграция с браузерных примитивов (BroadcastChannel, воркеры) на однопоточный Node.js.
- Обвязка: конфиг, загрузка/сохранение весов, файловая система.
- Временное отключение метрик (обёртки закомментированы, можно вернуть быстро).
- Удаление/замена только того кода, который напрямую блокирует работу в Node.
Не вносим рефакторинг в математическую часть / алгоритм, чтобы не искажать поведение модели до момента, когда базовый цикл стабилен.

#### Удаление клиентской генерации данных
В рамках выделения backend-а нужно убрать/вынести всё, что относится к порождению опыта на стороне клиента (UI/рендер, симуляция в браузере, визуальные отладочные панели). Backend ожидает уже готовые батчи опыта через Ably и сам ничего не симулирует. В репозитории:
- Код генерации кадров / игровых состояний не должен оставаться внутри `ml-backend`.
- Любые mocks/generators (кроме утилиты для синтетического теста) либо переносятся в отдельный пакет, либо удаляются.
- Оставляем только маленький скрипт синтетического наполнения буфера (для локальной проверки), помеченный как dev-утилита.

## Минимальный поток данных
`Clients -> (Ably channel: ml:experience.v1) -> ReplayBuffer -> (условие) train() -> обновление весов -> publish ml:model.weights.v1`

## Конфигурация
Источник значений: `config.ts` (жёстко + простая функция для override из env). В `.env` только ключи.

## Чекпоинты
- Сохраняем `model.json` и `weights.bin` в `CHECKPOINT_DIR/v{N}`.
- `N = previous + 1` (просто номер папки). Ротация/метаданные добавятся позже.

## Каналы (минимум)
- `ml:experience.v1` — вход.
- `ml:model.weights.v1` — сигнал о новой версии (payload: `{version}`).
- (опционально позже) `ml:control.v1` (`pause/resume`). Сейчас нет.

## Что отключено (осознанно)
- Метрики (KL, value/policy loss истории, success ratio, браузерные графики).

## Definition of Done (для MVP)
- Можно запустить и увидеть цикл: приём опыта → обучение → инкремент версии.
- Чекпоинт создаётся и используется после рестарта.
- Нет крэшей при непрерывной работе хотя бы 10–15 минут с синтетическим опытом.

## Короткая шпаргалка
1. Создай `.env` с ключом Ably.
2. Старт dev режима.
